# Talk to Transformer Project

#Dummy commit

## Objective
As the field of deep learning becomes more popular, there are many advancements in the subdivision of natural language processing (NLP). With the aid of pretrained language models, such as ELMo and BERT, tasks that require relationship between words have become much easier. Transformers, in particular, enable models to understand semantic relationships between words which make them perfect for text generation. The goal of this project is to develop a program that allows the user to communicate with a transformer. The end product is for the user to be able to talk into a microphone and the app responds with a speech generated by a transformer.

## Structure
The main pipeline of the Flask app consist of three stages: speech-to-text conversion, transformer model text generation, and text-to-speech converison. The user inputs a voice recording in a .WAV format as well as their desired length of response (between 1-300 words). Next, the app uses Google's speech recognition API to convert the audio file into text. Then, the converted text is passed into a GPT-2 transformer model along with the specified length of output by the user. The transformer returns a response which is passed into the Google's text-to-speech API. The API returns an audio file which is saved to the backend and played back to the user.

## Instructions

There are two ways to deploy the Flask app: on local machine and on the cloud app engine. 

### Local Deployment
```
git clone https://github.com/FourthTee/Talk-To-Transformer.git
cd Talk-To-Transformer
conda create -n talk-to-transformer python=3
pip install -r requirements.txt
python main.py
```

### Cloud Deployment (Google Cloud Platform)
Before deploying the app on GCP you will need to setup your gcloud project and enable billing for use of Cloud API
```
git clone https://github.com/FourthTee/Talk-To-Transformer.git
cd Talk-To-Transformer
gcloud app deploy
```
